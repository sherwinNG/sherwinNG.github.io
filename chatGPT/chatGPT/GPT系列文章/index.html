<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="sherwin"><meta name="keywords" content=""><meta name="description" content="GPT系列论文&amp;报告随时更新中英文全称：Generative Pre-trained Transformer演进历程：GPT-1(2018-06)：Improving Language Understanding by Generative Pre-trainingGPT-2(2019-02)：Language Models are unsupervised multitask lear"><meta property="og:type" content="article"><meta property="og:title" content="GPT系列论文&amp;报告"><meta property="og:url" content="http://sherwinzhang.com/chatGPT/chatGPT/GPT%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/index.html"><meta property="og:site_name" content="sherwinNG&#39;s blog"><meta property="og:description" content="GPT系列论文&amp;报告随时更新中英文全称：Generative Pre-trained Transformer演进历程：GPT-1(2018-06)：Improving Language Understanding by Generative Pre-trainingGPT-2(2019-02)：Language Models are unsupervised multitask lear"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://tc-sherwin.oss-cn-beijing.aliyuncs.com/img/image-20230523224012170.png"><meta property="article:published_time" content="2023-01-21T02:24:21.000Z"><meta property="article:modified_time" content="2023-05-27T16:21:45.149Z"><meta property="article:author" content="sherwin"><meta property="article:tag" content="chatGPT"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://tc-sherwin.oss-cn-beijing.aliyuncs.com/img/image-20230523224012170.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>GPT系列论文&amp;报告 - sherwinNG&#39;s blog</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var dntVal,Fluid=window.Fluid||{},CONFIG=(Fluid.ctx=Object.assign({},Fluid.ctx),{hostname:"sherwinzhang.com",root:"/",version:"1.9.3",typing:{enable:!0,typeSpeed:70,cursorChar:"--",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"});CONFIG.web_analytics.follow_dnt&&(dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on")))</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="sherwinNG's blog" type="application/atom+xml"></head><body><header><div class="header-inner" style="height:100vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>【文言】</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><i class="iconfont icon-books"></i> 文档</a><div class="dropdown-menu" aria-labelledby="navbarDropdown"><a class="dropdown-item" href="https://hexo.fluid-dev.com/" target="_blank" rel="noopener">主题博客 </a><a class="dropdown-item" href="https://hexo.fluid-dev.com/docs/guide/" target="_blank" rel="noopener">配置指南 </a><a class="dropdown-item" href="https://hexo.fluid-dev.com/docs/icon/" target="_blank" rel="noopener">图标用法</a></div></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="GPT系列论文&amp;报告"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-01-21 10:24" pubdate>2023年1月21日 上午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 1.9k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 10 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div><div class="scroll-down-bar"><i class="iconfont icon-arrowdown"></i></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">GPT系列论文&amp;报告</h1><div class="markdown-body"><h1 id="gpt系列论文报告"><a class="markdownIt-Anchor" href="#gpt系列论文报告"></a> GPT系列论文&amp;报告</h1><blockquote><p>随时更新中</p></blockquote><p>英文全称：Generative Pre-trained Transformer</p><p>演进历程：</p><ul><li>GPT-1(2018-06)：<a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">Improving Language Understanding by Generative Pre-training</a></li><li>GPT-2(2019-02)：<a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">Language Models are unsupervised multitask learners</a></li><li>GPT-3(2020-05)：<a href="https://arxiv.org/pdf/2005.14165.pdf" target="_blank" rel="noopener">Language models are few shot learners</a></li></ul><blockquote><p>GPT主要是基于 Google 2017-06发出的《Attention is All Your Need》文章中 Transformer 的 decoder 架构，2018-06 提出了第一版GPT模型，2018-10 Google 提出了Bert 模型。</p></blockquote><p>GPT可以实现功能：</p><ul><li>可以实现文本补全、代码补全、翻译、自然语言到计算机语言的转换、聊天等</li><li>功能非常多，具体可以参考官网：<a href="https://platform.openai.com/examples" target="_blank" rel="noopener">https://platform.openai.com/examples</a></li></ul><h2 id="原论文报告"><a class="markdownIt-Anchor" href="#原论文报告"></a> 原论文&amp;报告</h2><h3 id="gpt-1"><a class="markdownIt-Anchor" href="#gpt-1"></a> GPT-1</h3><p>论文链接：<a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">GPT-1</a></p><p>在GPT-1之前（和ELMo同一年），传统的NLP模型往往使用大量的数据对有监督的模型进行任务相关的模型训练，但是这种有监督学习的任务存在两个缺点：</p><ol><li>需要大量的标注数据，而高质量的标注数据往往很难获得，一方面需要很多专业的技术人员做标注，另一方面数据的获取非常昂贵。</li><li>根据一个任务训练的模型很难泛化到其它任务中，这个模型只能叫做“领域专家”而不是真正的理解了NLP。</li></ol><p>GPT-1的思想是先通过在无标签的数据上学习一个生成式的语言模型，然后再根据特定的任务进行微调，处理的有监督任务包括：</p><ol><li>自然语言推理</li><li>问答和常识推理</li><li>语义相似度</li><li>分类</li></ol><p>总结来说，GPT-1就是无监督训练+有监督微调。</p><h3 id="gpt-2"><a class="markdownIt-Anchor" href="#gpt-2"></a> GPT-2</h3><p>论文链接：<a href="https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf" target="_blank" rel="noopener">GPT-2</a></p><p>GPT-2的目标旨在训练一个泛化能力更强的词向量模型，它并没有对GPT-1的网络进行过多的结构的创新与设计，只是使用了更多的网络参数和更大的数据集。GPT-2的学习目标是<strong>使用无监督的预训练模型做有监督的任务</strong>。当一个语言模型足够大时，它就足矣覆盖所有的有监督任务，即所有的有监督学习都是无监督语言模型的一个子集。</p><p>GPT-2的最大贡献是验证了通过海量数据和大量参数训练出来的词向量模型有迁移到其它类别任务中而不需要额外的训练。但是很多实验也表明，GPT-2的无监督学习的能力还有很大的提升空间。</p><h3 id="gpt-3"><a class="markdownIt-Anchor" href="#gpt-3"></a> GPT-3</h3><p>论文链接：<a href="https://arxiv.org/pdf/2005.14165.pdf" target="_blank" rel="noopener">GPT-3</a></p><p>GPT3的参数量达到了海量级别，1750亿的参数量，45TB的训练数据使得它成为2020年最强大的语言模型。</p><p>In-context learning是这篇论文中介绍的一个重要概念，它在GPT3中类似于内循环，而针对不同任务的整体优化则是外循环。</p><p>在大量的语言模型数据集中，GPT-3超过了绝大多数的zero-shot或者few-shot的state-of-the-art方法。另外GPT-3在很多复杂的NLP任务中也超过了fine-tune之后的state-of-the-art方法，例如闭卷问答，模式解析，机器翻译等。除了这些传统的NLP任务，GPT-3在一些其他的领域也取得了非常震惊的效果，例如进行数学加法，文章生成，编写代码等。</p><h3 id="gpt-35"><a class="markdownIt-Anchor" href="#gpt-35"></a> GPT-3.5</h3><p>论文链接：<a href="https://arxiv.org/pdf/2203.02155.pdf" target="_blank" rel="noopener">GPT-3.5</a></p><p>GPT3.5，也就是InstructGPT/ChatGPT，他们采用了<strong>GPT-3</strong>的网络结构，通过<strong>指示学习</strong>构建训练样本来训练一个反应预测内容效果的奖励模型（RM），最后通过这个奖励模型的打分来指导强化学习模型的训练。这个训练过程主要分为三步：</p><ol><li>根据采集的SFT数据集对GPT-3进行有监督的微调（Supervised FineTune，SFT）；</li><li>收集人工标注的对比数据，训练奖励模型（Reword Model，RM）；</li><li>使用RM作为强化学习的优化目标，利用PPO算法微调SFT模型。</li></ol><p><img src="https://tc-sherwin.oss-cn-beijing.aliyuncs.com/img/image-20230523224012170.png" srcset="/img/loading.gif" lazyload alt=""></p><p>GPT3.5引入了人工标注之后，让模型的“价值观”和的正确程度和人类行为模式的“真实性”上都大幅的提升。</p><h3 id="gpt-4"><a class="markdownIt-Anchor" href="#gpt-4"></a> GPT-4</h3><p>技术报告：<a href="https://arxiv.org/pdf/2303.08774.pdf" target="_blank" rel="noopener">GPT-4</a></p><p>结论：</p><ol><li>GPT-4朝着AGI迈出了坚实一步，但离AGI仍然遥远。</li><li>GPT-4的智能模式与人类智能具有非常大的差异。</li><li>GPT-4无法创造新知识</li><li>GPT-4能够从纯文本中产生视觉概念</li><li>GPT-4在代码理解上的能力达到前所未有的高度</li><li>在数学计算能力上远远落后于其他能力</li><li>GPT-4仍然缺乏常识</li><li>GPT-4能够使用工具在外部世界进行交互，但仍然存在一些典型问题</li><li>GPT-4在理解意图、情绪方面具有显著进步</li><li>由于GPT-4采用的自回归结构，导致它在规划能力上、working memory上明显不足。</li><li>GPT-4导致的社会问题主要包括错误答案、被错误使用、偏见和进一步加剧不平等。</li></ol></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/chatGPT/" class="category-chain-item">chatGPT</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/chatGPT/">#chatGPT</a></div></div><div class="license-box my-3"><div class="license-title"><div>GPT系列论文&amp;报告</div><div>http://sherwinzhang.com/chatGPT/chatGPT/GPT系列文章/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>sherwin</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年1月21日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/chatGPT/chatGPT/chatGPT-api/" title="chatGPT API使用以及参数说明"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">chatGPT API使用以及参数说明</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E9%80%9A%E4%BF%97%E4%BB%8B%E7%BB%8D/" title="推荐系统通俗介绍"><span class="hidden-mobile">推荐系统通俗介绍</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="lv-container" data-id="city" data-uid="MTAyMC81NzExNy8zMzU4MQ=="><script type="text/javascript">Fluid.utils.loadComments("#lv-container",function(){Fluid.utils.createScript("https://cdn-city.livere.com/js/embed.dist.js")})</script><noscript>Please enable JavaScript to view the comments</noscript></div></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div><div class="beian"><span><a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">京ICP证1024号 </a></span><span><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=10241024" rel="nofollow noopener" class="beian-police" target="_blank"><span style="visibility:hidden;width:0">|</span> <img src="/img/police_beian.png" srcset="/img/loading.gif" lazyload alt="police-icon"> <span>京公网安备1024号</span></a></span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t){var e=Fluid.plugins.typing;(t=t.getElementById("subtitle"))&&e&&e(t.getAttribute("data-typed-text"))}((window,document))</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",function(){var t,o=jQuery("#toc");0!==o.length&&window.tocbot&&(t=jQuery("#board-ctn").offset().top,window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-t},CONFIG.toc)),0<o.find(".toc-list-item").length&&o.css("visibility","visible"),Fluid.events.registerRefreshCallback(function(){var t;"tocbot"in window&&(tocbot.refresh(),0!==(t=jQuery("#toc")).length&&tocbot&&0<t.find(".toc-list-item").length&&t.css("visibility","visible"))}))})</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback(function(){if("anchors"in window){anchors.removeAll();var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}})})</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",function(){Fluid.plugins.fancyBox()})</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>