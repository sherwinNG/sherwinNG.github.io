{"meta":{"title":"sherwinNG's blog","subtitle":"遇见更好的自己","description":"The way of the future!","author":"sherwin","url":"http://sherwinzhang.com","root":"/"},"pages":[{"title":"404","date":"2020-02-19T01:33:16.829Z","updated":"2020-02-19T01:33:16.829Z","comments":true,"path":"404.html","permalink":"http://sherwinzhang.com/404.html","excerpt":"","text":"这是网页标题"},{"title":"友情链接","date":"2022-05-13T11:18:25.293Z","updated":"2022-03-21T07:18:46.000Z","comments":true,"path":"links/index.html","permalink":"http://sherwinzhang.com/links/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-05-13T11:11:29.745Z","updated":"2022-03-21T07:18:46.000Z","comments":false,"path":"categories/index.html","permalink":"http://sherwinzhang.com/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-05-13T09:28:31.824Z","updated":"2022-05-13T09:28:31.824Z","comments":false,"path":"about/index.html","permalink":"http://sherwinzhang.com/about/index.html","excerpt":"","text":"个人详细介绍12&#123;你好&#125;"},{"title":"标签","date":"2022-05-13T11:13:05.230Z","updated":"2022-03-21T07:18:46.000Z","comments":false,"path":"tags/index.html","permalink":"http://sherwinzhang.com/tags/index.html","excerpt":"","text":""},{"title":"书单","date":"2022-05-13T11:16:16.622Z","updated":"2022-03-21T07:18:46.000Z","comments":false,"path":"books/index.html","permalink":"http://sherwinzhang.com/books/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-05-13T11:14:26.657Z","updated":"2022-03-21T07:18:46.000Z","comments":false,"path":"repository/index.html","permalink":"http://sherwinzhang.com/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"数据分割介绍","slug":"数据分割介绍","date":"2021-06-12T01:14:21.000Z","updated":"2022-05-13T01:54:43.211Z","comments":true,"path":"2021/06/12/数据分割介绍/","link":"","permalink":"http://sherwinzhang.com/2021/06/12/%E6%95%B0%E6%8D%AE%E5%88%86%E5%89%B2%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"在机器学习中，我们可通过实验测试来对学习器的泛化误差进行评估并进而做出选择。为此，需使用一个“测试集”( testing set)来测试学习器对新样本的判别能力，然后以测试集上的“测试误差” (testing error)作为泛化误差的近似。通常我们假设测试样本也是从样本真实分布中独立同分布采样而得。但需注意的是，测试集应该尽可能与训练集互斥。互斥，即测试样本尽量不在训练集中出现、未在训练过程中使用过。测试样本为什么要尽可能不出现在训练集中呢？为理解这一点，不妨考虑这样一个场景:老师出了10道习题供同学们练习，考试时老师又用同样的这10道题作为试题，这个考试成绩能否有效反映出同学们学得好不好呢？答案是否定的，可能有的同学只会做这10道题却能得高分。回到我们的问题上来，我们希望得到泛化性能强的模型，好比是希望同学们对课程学得很好、获得了对所学知识“举一反三”的能力；训练样本相当于给同学们练习的习题，测试过程则相当于考试。显然，若测试样本被用作训练了，则得到的将是过于“乐观”的估计结果。可是，我们只有一个包含m个样例的数据集既要训练，又要测试，怎样才能做到呢？答案是:通过对D进行适当的处理，从中产生出训练集S和测试集T。（这个也是我们前面一直在做的事情）。下面我们一起总结一下几种常见的做法：留出法交叉验证法自助法 1 留出法“留出法”(hold-out)直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，即。在S上训练出模型后，用T来评估其测试误差，作为对泛化误差的估计。大家在使用的过程中，需注意的是，训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响，例如在分类任务中至少要保持样本的类别比例相似。如果从采样( sampling)的角度来看待数据集的划分过程，则保留类别比例的采样方式通常称为**“分层采样”( stratified sampling)。**例如通过对D进行分层样而获得含70%样本的训练集S和含30%样本的测试集T，若D包含500个正例、500个反例，则分层采样得到的S应包含350个正例、350个反例，而T则包含150个正例和150个反例；若S、T中样本类别比例差别很大，则误差估计将由于训练/测试数据分布的差异而产生偏差。另一个需注意的问题是，即便在给定训练测试集的样本比例后，仍存在多种划分方式对初始数据集D进行分割。例如在上面的例子中，可以把D中的样本排序，然后把前350个正例放到训练集中，也可以把最后350个正例放到训练集中，这些不同的划分将导致不同的训练/测试集，相应的，模型评估的结果也会有差别。因此，单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。例如进行100次随机划分，每次产生一个训练/测试集用于实验评估，100次后就得到100个结果，而留出法返回的则是这100个结果的平均。此外，我们希望评估的是用D训练出的模型的性能，但留出法需划分训练/测试集，这就会导致一个窘境:若令训练集S包含绝大多数样本，则训练出的模型可能更接近于用D训练出的模型，但由于T比较小，评估结果可能不够稳定准确；若令测试集T多包含一些样本，则训练集S与D差别更大了，被评估的模型与用D训练出的模型相比可能有较大差别，从而降低了评估结果的保真性( fidelity)。这个问题没有完美的解决方案，常见做法是将大约2/3~4/5的样本用于训练，剩余样本用于测试。使用Python实现留出法：1234from sklearn.model_selection import train_test_split#使用train_test_split划分训练集和测试集train_X , test_X, train_Y ,test_Y = train_test_split( X, Y, test_size=0.2,random_state=0)在留出法中，有一个特例，叫：留一法( Leave-One-Out，简称LOO），即每次抽取一个样本做为测试集。显然，留一法不受随机样本划分方式的影响，因为m个样本只有唯一的方式划分为m个子集一每个子集包含个样本；使用Python实现留一法：123456789101112from sklearn.model_selection import LeaveOneOutdata = [1, 2, 3, 4]loo = LeaveOneOut()for train, test in loo.split(data): print(\"%s %s\" % (train, test))'''结果[1 2 3] [0][0 2 3] [1][0 1 3] [2][0 1 2] [3]'''留一法优缺点：优点：留一法使用的训练集与初始数据集相比只少了一个样本，这就使得在绝大多数情况下，留一法中被实际评估的模型与期望评估的用D训练出的模型很相似。因此，留一法的评估结果往往被认为比较准确。缺点：留一法也有其缺陷:在数据集比较大时，训练m个模型的计算开销可能是难以忍受的(例如数据集包含1百万个样本，则需训练1百万个模型，而这还是在未考虑算法调参的情况下。 2 交叉验证法“交叉验证法”( cross validation)先将数据集D划分为k个大小相似的互斥子集，即。每个子集$$D_i$$都尽可能保持数据分布的一致性，即从D中通过分层抽样得到。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值。显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值，为强调这一点，通常把交叉验证法称为“k折交叉验证”(k- fold cross validation)。k最常用的取值是10，此时称为10折交叉验证；其他常用的k值有5、20等。下图给出了10折交叉验证的示意图。**与留出法相似，将数据集D划分为k个子集同样存在多种划分方式。**为减小因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值，例如常见的有“10次10折交叉验证”。交叉验证实现方法，除了咱们前面讲的GridSearchCV之外，还有KFold, StratifiedKFold KFold和StratifiedKFold1from sklearn.model_selection import KFold,StratifiedKFold用法：将训练/测试数据集划分n_splits个互斥子集，每次用其中一个子集当作验证集，剩下的n_splits-1个作为训练集，进行n_splits次训练和测试，得到n_splits个结果StratifiedKFold的用法和KFold的区别是：SKFold是分层采样，确保训练集，测试集中，各类别样本的比例是和原始数据集中的一致。注意点：对于不能均等分数据集，其前n_samples % n_splits子集拥有n_samples // n_splits + 1个样本，其余子集都只有n_samples // n_splits样本参数说明：n_splits：表示划分几等份shuffle：在每次划分时，是否进行洗牌①若为Falses时，其效果等同于random_state等于整数，每次划分的结果相同②若为True时，每次划分的结果都不一样，表示经过洗牌，随机取样的属性：①split(X, y=None, groups=None)：将数据集划分成训练集和测试集，返回索引生成器1234567891011121314151617181920212223242526import numpy as npfrom sklearn.model_selection import KFold,StratifiedKFoldX = np.array([ [1,2,3,4], [11,12,13,14], [21,22,23,24], [31,32,33,34], [41,42,43,44], [51,52,53,54], [61,62,63,64], [71,72,73,74]])y = np.array([1,1,0,0,1,1,0,0])folder = KFold(n_splits = 4, random_state=0, shuffle = False)sfolder = StratifiedKFold(n_splits = 4, random_state = 0, shuffle = False) for train, test in folder.split(X, y): print('train:%s | test:%s' %(train, test)) print(\"\") for train, test in sfolder.split(X, y): print('train:%s | test:%s'%(train, test)) print(\"\")结果：1234567891011121314151617# 第一个for，输出结果为：train:[2 3 4 5 6 7] | test:[0 1]train:[0 1 4 5 6 7] | test:[2 3]train:[0 1 2 3 6 7] | test:[4 5]train:[0 1 2 3 4 5] | test:[6 7]# 第二个for，输出结果为：train:[1 3 4 5 6 7] | test:[0 2]train:[0 2 4 5 6 7] | test:[1 3]train:[0 1 2 3 5 7] | test:[4 6]train:[0 1 2 3 4 6] | test:[5 7]可以看出，sfold进行4折计算时候，是平衡了测试集中，样本正负的分布的；但是fold却没有。 3 自助法我们希望评估的是用D训练出的模型。但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此**实际评估的模型所使用的训练集比D小，**这必然会引入一些因训练样本规模不同而导致的估计偏差。留一法受训练样本规模变化的影响较小，但计算复杂度又太高了。有没有什么办法可以减少训练样本规模不同造成的影响，同时还能比较高效地进行实验估计呢？“自助法”( bootstrapping)是一个比较好的解决方案，它直接以自助采样法( bootstrap sampling)为基础。给定包含m个样本的数据集D，我们对它进行采样产生数据集D:每次随机从D中挑选一个样本，将其拷贝放入D，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被到；这个过程重复执行m次后，我们就得到了包含m个样本的数据集D′，这就是自助采样的结果。显然，D中有一部分样本会在D′中多次出现，而另一部分样本不出现。可以做一个简单的估计，样本在m次采样中始终不被采到的概率是$$(1-\\frac{1}{m})^m$$，取极限得到即通过自助采样，初始数据集D中约有36.8%的样本未出现在采样数据集D′中。于是我们可将D′用作训练集，D\\D′用作测试集；这样，实际评估的模型与期望评估的模型都使用m个训练样本，而我们仍有数据总量约1/3的、没在训练集中出现的样本用于测试。这样的测试结果，亦称**“包外估计”(out- of-bagestimate）**自助法优缺点：优点：自助法在数据集较小、难以有效划分训练/测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。缺点：自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时；留出法和交叉验证法更常用一些。 4 总结综上所述：当我们数据量足够时，选择留出法简单省时，在牺牲很小的准确度的情况下，换取计算的简便；当我们的数据量较小时，我们应该选择交叉验证法，因为此时划分样本集将会使训练数据过少；当我们的数据量特别少的时候，我们可以考虑留一法。","categories":[{"name":"AI","slug":"AI","permalink":"http://sherwinzhang.com/categories/AI/"},{"name":"ML","slug":"AI/ML","permalink":"http://sherwinzhang.com/categories/AI/ML/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://sherwinzhang.com/tags/ML/"}]},{"title":"分类中解决类别不平衡问题","slug":"分类中解决类别不平衡问题","date":"2019-06-10T02:24:21.000Z","updated":"2022-05-13T11:30:12.962Z","comments":true,"path":"2019/06/10/分类中解决类别不平衡问题/","link":"","permalink":"http://sherwinzhang.com/2019/06/10/%E5%88%86%E7%B1%BB%E4%B8%AD%E8%A7%A3%E5%86%B3%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98/","excerpt":"","text":"分类中解决类别不平衡问题其实，在现实环境中，采集的数据（建模样本）往往是比例失衡的。比如网贷数据，逾期人数的比例是极低的（千分之几的比例）；奢侈品消费人群鉴定等。 1 类别不平衡数据集基本介绍当遇到数据类别不平衡的时候，我们该如何处理。在Python中，有Imblearn包，它就是为处理数据比例失衡而生的。安装Imblearn包1pip3 install imbalanced-learn第三方包链接：https://pypi.org/project/imbalanced-learn/创造数据集12345678910111213from sklearn.datasets import make_classificationimport matplotlib.pyplot as plt#使用make_classification生成样本数据X, y = make_classification(n_samples=5000, n_features=2, # 特征个数= n_informative（） + n_redundant + n_repeated n_informative=2, # 多信息特征的个数 n_redundant=0, # 冗余信息，informative特征的随机线性组合 n_repeated=0, # 重复信息，随机提取n_informative和n_redundant 特征 n_classes=3, # 分类类别 n_clusters_per_class=1, # 某一个类别是由几个cluster构成的 weights=[0.01, 0.05, 0.94], # 列表类型，权重比 random_state=0)查看各个标签的样本12345#查看各个标签的样本量from collections import CounterCounter(y)# Counter(&#123;2: 4674, 1: 262, 0: 64&#125;)数据集可视化123# 数据集可视化plt.scatter(X[:, 0], X[:, 1], c=y)plt.show()可以看出样本的三个标签中，1，2的样本量极少，样本失衡。下面使用imblearn进行过采样。接下来，我们就要基于以上数据，进行相应的处理。关于类别不平衡的问题，主要有两种处理方式：过采样方法增加数量较少那一类样本的数量，使得正负样本比例均衡。欠采样方法减少数量较多那一类样本的数量，使得正负样本比例均衡。 2 解决类别不平衡数据方法介绍 2.1 过采样方法 2.1.1 什么是过采样方法对训练集里的少数类进行“过采样”（oversampling），即增加一些少数类样本使得正、反例数目接近，然后再进行学习。 2.1.2 随机过采样方法随机过采样是在少数类 中随机选择一些样本，然后**通过复制所选择的样本生成样本集 ，**将它们添加到 中来扩大原始数据集从而得到新的少数类集合 。新的数据集 。通过代码实现随机过采样方法：12345678910111213# 使用imblearn进行随机过采样from imblearn.over_sampling import RandomOverSamplerros = RandomOverSampler(random_state=0)X_resampled, y_resampled = ros.fit_resample(X, y)#查看结果Counter(y_resampled) #过采样后样本结果# Counter(&#123;2: 4674, 1: 4674, 0: 4674&#125;)# 数据集可视化plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled)plt.show()缺点：对于随机过采样，由于需要对少数类样本进行复制来扩大数据集，造成模型训练复杂度加大。另一方面也容易造成模型的过拟合问题，因为随机过采样是简单的对初始样本进行复制采样，这就使得学习器学得的规则过于具体化，不利于学习器的泛化性能，造成过拟合问题。为了解决随机过采样中造成模型过拟合问题，又能保证实现数据集均衡的目的，出现了过采样法代表性的算法SMOTE算法。 2.1.3 过采样代表性算法-SMOTESMOTE全称是Synthetic Minority Oversampling即合成少数类过采样技术。SMOTE算法是对随机过采样方法的一个改进算法，由于随机过采样方法是直接对少数类进行重采用，会使训练集中有很多重复的样本，容易造成产生的模型过拟合问题。而SMOTE算法的基本思想是对每个少数类样本 ，从它的最近邻中随机选择一个样本 （ 是少数类中的一个样本），然后在 和 之间的连线上随机选择一点作为新合成的少数类样本。SMOTE算法合成新少数类样本的算法描述如下：对于少数类中的每一个样本 ，以欧氏距离为标准计算它到少数类样本集 中所有样本的距离，得到其k近邻。根据样本不平衡比例设置一个采样比例以确定采样倍率N，对于每一个少数类样本 ，从其k近邻中随机选择若干个样本，假设选择的是 。对于每一个随机选出来的近邻 ，分别与 按照如下公式构建新的样本。我们用图文表达的方式，再来描述一下SMOTE算法。先随机选定一个少数类样本 。找出这个少数类样本 的K个近邻（假设K=5），5个近邻已经被圈出。随机从这K个近邻中选出一个样本 （用绿色圈出来了）。4)在少数类样本 和被选中的这个近邻样本 之间的连线上，随机找一点。这个点就是人工合成的新的样本点（绿色正号标出）。SMOTE算法摒弃了随机过采样复制样本的做法，可以防止随机过采样中容易过拟合的问题，实践证明此方法可以提高分类器的性能。代码实现：1234567891011# SMOTE过采样from imblearn.over_sampling import SMOTEX_resampled, y_resampled = SMOTE().fit_resample(X, y)Counter(y_resampled)# 采样后样本结果# [(0, 4674), (1, 4674), (2, 4674)]# 数据集可视化plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled)plt.show() 2.2 欠采样方法 2.2.1 什么是欠采样方法直接对训练集中多数类样本进行“欠采样”（undersampling），即去除一些多数类中的样本使得正例、反例数目接近，然后再进行学习。 2.2.2 随机欠采样方法随机欠采样顾名思义即从多数类 中随机选择一些样样本组成样本集 。然后将样本集 从 中移除。新的数据集 。代码实现：123456789101112# 随机欠采样from imblearn.under_sampling import RandomUnderSamplerrus = RandomUnderSampler(random_state=0)X_resampled, y_resampled = rus.fit_resample(X, y)Counter(y_resampled)# 采样后结果[(0, 64), (1, 64), (2, 64)]# 数据集可视化plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled)plt.show()缺点：随机欠采样方法通过改变多数类样本比例以达到修改样本分布的目的，从而使样本分布较为均衡，但是这也存在一些问题。对于随机欠采样，由于采样的样本集合要少于原来的样本集合，因此会造成一些信息缺失，即将多数类样本删除有可能会导致分类器丢失有关多数类的重要信息。官网链接：https://imbalanced-learn.readthedocs.io/en/stable/ensemble.html","categories":[{"name":"AI","slug":"AI","permalink":"http://sherwinzhang.com/categories/AI/"},{"name":"ML","slug":"AI/ML","permalink":"http://sherwinzhang.com/categories/AI/ML/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://sherwinzhang.com/tags/ML/"}]},{"title":"独立同分布","slug":"独立同分布","date":"2019-06-08T02:24:21.000Z","updated":"2020-03-11T08:08:18.430Z","comments":true,"path":"2019/06/08/独立同分布/","link":"","permalink":"http://sherwinzhang.com/2019/06/08/%E7%8B%AC%E7%AB%8B%E5%90%8C%E5%88%86%E5%B8%83/","excerpt":"","text":"独立同分布IID(independent and identically distributed) 1 独立同分布(i.i.d.)在概率统计理论中，如果变量序列或者其他随机变量有相同的概率分布，并且互相独立，那么这些随机变量是独立同分布。在西瓜书中解释是：输入空间中的所有样本服从一个隐含未知的分布，训练数据所有样本都是独立地从这个分布上采样而得。 2 简单解释 — 独立、同分布、独立同分布（1）独立：每次抽样之间没有关系，不会相互影响举例：给一个骰子，每次抛骰子抛到几就是几，这是独立；如果我要抛骰子两次之和大于8，那么第一次和第二次抛就不独立，因为第二次抛的结果和第一次相关。（2）同分布：每次抽样，样本服从同一个分布举例：给一个骰子，每次抛骰子得到任意点数的概率都是六分之一，这个就是同分布（3）独立同分布：i.i.d.，每次抽样之间独立而且同分布 3 机器学习领域的重要假设IID独立同分布即假设训练数据和测试数据是满足相同分布的，它是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障。 4 目前发展机器学习并不总要求独立同分布，在不少问题中要求样本数据采样自同一个分布是因为希望用训练数据集得到的模型可以合理的用于测试数据集，使用独立同分布假设能够解释得通。目前一些机器学习内容已经不再囿于独立同分布假设下，一些问题会假设样本没有同分布。","categories":[{"name":"AI","slug":"AI","permalink":"http://sherwinzhang.com/categories/AI/"},{"name":"ML","slug":"AI/ML","permalink":"http://sherwinzhang.com/categories/AI/ML/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://sherwinzhang.com/tags/ML/"}]},{"title":"完整机器学习项目的流程","slug":"AI/ML/完整机器学习项目的流程","date":"2019-06-04T01:14:21.000Z","updated":"2020-03-10T16:11:52.567Z","comments":true,"path":"2019/06/04/AI/ML/完整机器学习项目的流程/","link":"","permalink":"http://sherwinzhang.com/2019/06/04/AI/ML/%E5%AE%8C%E6%95%B4%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%B5%81%E7%A8%8B/","excerpt":"","text":"完整机器学习项目的流程 1 抽象成数学问题明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。这里的抽象成数学问题，指的明确我们可以获得什么样的数据，抽象出的问题，是一个分类还是回归或者是聚类的问题。 2 获取数据数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。数据要有代表性，否则必然会过拟合。而且对于分类问题，数据偏斜不能过于严重，不同类别的数据数量不要有数量级的差距。而且还要对数据的量级有一个评估，多少个样本，多少个特征，可以估算出其对内存的消耗程度，判断训练过程中内存是否能够放得下。如果放不下就得考虑改进算法或者使用一些降维的技巧了。如果数据量实在太大，那就要考虑分布式了。 3 特征预处理与特征选择良好的数据要能够提取出良好的特征才能真正发挥作用。特征预处理、数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。 4 训练模型与调优直到这一步才用到我们上面说的算法进行训练。现在很多算法都能够封装成黑盒供人使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优良。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。 5 模型诊断如何确定模型调优的方向与思路呢？这就需要对模型进行诊断的技术。过拟合、欠拟合 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。误差分析 也是机器学习至关重要的步骤。通过观察误差样本全面分析产生误差的原因:是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题……诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。 6 模型融合一般来说，模型融合后都能使得效果有一定提升。而且效果很好。工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。 7 上线运行这一部分内容主要跟工程实现的相关性比较大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。 不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。这些工作流程主要是工程实践上总结出的一些经验。并不是每个项目都包含完整的一个流程。这里的部分只是一个指导性的说明，只有大家自己多实践，多积累项目经验，才会有自己更深刻的认识。","categories":[{"name":"AI","slug":"AI","permalink":"http://sherwinzhang.com/categories/AI/"},{"name":"ML","slug":"AI/ML","permalink":"http://sherwinzhang.com/categories/AI/ML/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://sherwinzhang.com/tags/ML/"}]}],"categories":[{"name":"AI","slug":"AI","permalink":"http://sherwinzhang.com/categories/AI/"},{"name":"ML","slug":"AI/ML","permalink":"http://sherwinzhang.com/categories/AI/ML/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://sherwinzhang.com/tags/ML/"}]}